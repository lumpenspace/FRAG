embeds:
  default_collection: default # name of the default collection
  api_model: text-embedding-3-large # Name of the embedding model.
                                   # for HuggingFace,
                                   # see https://www.sbert.net/docs/pretrained_models.html
                                   # for OpenAI, see https://platform.openai.com/docs/models
  api_source: OpenAI # source of the embedding model. can be OpenAI or HuggingFace
  # also available: 
  # max_tokens(int), to set the maximum number of tokens to embed
bots:
  api: gpt-3.5-turbo # see: https://litellm.vercel.app/docs/providers
  # we use the lite-llm default settings unless the user specifies otherwise,
  interface: { api: gpt-4-turbo } # these settings override top-level settings for the interface bot
  # you can also specify other bot-specific settings, e.g.
  # summarizer: { max_tokens: 200 }
  # extractor: { api: gpt-3.5-turbo }

